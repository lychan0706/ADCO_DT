import requests
from bs4 import BeautifulSoup
import re

#def remove_emojis(text):
    #emoji_pattern = re.compile(
        #"[\U00010000-\U0010FFFF" # ìœ ë‹ˆì½”ë“œ ì´ëª¨í‹°ì½˜ ë²”ìœ„
        #"\U0001F600-\U0001F64F" # ì›ƒëŠ” ì–¼êµ´ ë° ê°ì •
        #"\U0001F300-\U0001F5FF" # ê¸°í˜¸ ë° í”½í† ê·¸ë¨
        #"\U0001F680-\U0001F6FF" # êµí†µ ë° ì§€ë„ ê¸°í˜¸
        #"\U0001F700-\U0001F77F" # ì•Œì¼€ë¯¸ ê¸°í˜¸
        #"\U0001F780-\U0001F7FF" # ê¸°íƒ€ ê¸°í˜¸
        #"\U0001F800-\U0001F8FF" # ì¶”ê°€ ê¸°í˜¸
        #"\U0001F900-\U0001F9FF" # ì†ë™ì‘ ë° ì¶”ê°€ ì´ëª¨í‹°ì½˜
        #"\U0001FA00-\U0001FAFF" # ë„êµ¬ ë° ê°ì²´
        #"\U00002702-\U000027B0" # ê¸°í˜¸
        #"\U0001F1E6-\U0001F1FF" # êµ­ê¸°
        #"\U00002600-\U000026FF" # ì¶”ê°€ ê¸°í˜¸ ë° ê¸°í˜¸ í™•ì¥
        #"\U00002700-\U000027BF" # ì¶”ê°€ ê¸°í˜¸ ë° ê¸°í˜¸ í™•ì¥
        #"\U0001F550-\U0001F567" # ì‹œê³„ ì´ëª¨í‹°ì½˜
        #"\U00002728"            # ë³„: âœ¨
        #"\U00002B50"            # ë³„: â­
        #"\U00002605-\U00002606" # ë³„: â˜…, â˜†
        #"\U0000231A-\U0000231B"   # ì†ëª©ì‹œê³„ (âŒš) ë° ëª¨ë˜ì‹œê³„ (âŒ›)
        #"\U0001F570"              # ê¸°íƒ€ ì‹œê³„ ì´ëª¨í‹°ì½˜ (ğŸ•°ï¸)
        #"\u200d"                  # Zero Width Joiner (ê¸€ì ì—°ê²° ê¸°í˜¸)
        #"\ufe0f"                  # Variation Selector (ì´ëª¨í‹°ì½˜ ë³€í˜•)
        #"]+",  # ìœ ë‹ˆì½”ë“œ ì´ëª¨í‹°ì½˜ ë²”ìœ„
        #flags=re.UNICODE,
    #)   
    #return emoji_pattern.sub(r"", text)

    ##emoji_pattern = re.compile(
    ##    "[\U00010000-\U0010FFFF]",  # ìœ ë‹ˆì½”ë“œ ì´ëª¨í‹°ì½˜ ë²”ìœ„
    ##    flags=re.UNICODE,
    ##)
    ##return emoji_pattern.sub(r"", text)

    #"\U000024C2-\U0001F251"  # ê¸°íƒ€

def filter_allowed_characters(text):
    # í—ˆìš© ë²”ìœ„: í•œê¸€, ì˜ë¬¸ì, ìˆ«ì, ê³µë°±, íŠ¹ì • ê¸°í˜¸
    allowed_pattern = re.compile(r"[^a-zA-Z0-9ã„±-ã…ê°€-í£\s!@#$%^&*()\-_=+\[\]{};:'\",.<>/?\\|`~]")
    return allowed_pattern.sub(" ", text)

def fix_spacing(text):
    # 1. ë¬¸ì¥ë¶€í˜¸ ë’¤ì— ê³µë°± ì¶”ê°€
    text = re.sub(r"([.,!?])(?=\S)", r"\1 ", text)

    # 2. ìˆ«ìì™€ ë¬¸ì ì‚¬ì´ì— ê³µë°± ì¶”ê°€
    text = re.sub(r"(\d)([ê°€-í£a-zA-Z])", r"\1 \2", text)
    text = re.sub(r"([ê°€-í£a-zA-Z])(\d)", r"\1 \2", text)

    # 3. ì˜ì–´ ë‹¨ì–´ì™€ í•œê¸€ ì‚¬ì´ì— ê³µë°± ì¶”ê°€
    text = re.sub(r"([a-zA-Z])([ê°€-í£])", r"\1 \2", text)
    text = re.sub(r"([ê°€-í£])([a-zA-Z])", r"\1 \2", text)

    # 4. ì—°ì†ëœ ê³µë°±ì„ í•˜ë‚˜ë¡œ ì¤„ì„
    text = re.sub(r"\s+", " ", text).strip()

    return text


def remove_substring(input_string, substring_to_remove):
    return input_string.replace(substring_to_remove, " ")

def crawler(url : str) -> tuple[str]: # ì„ì‹œ í•¨ìˆ˜
    try:
        # URL í™•ì¸
        if "blog.naver.com" not in url:
            return None
        
        # HTML ê°€ì ¸ì˜¤ê¸°
        response = requests.get(url)

        if response.status_code != 200:
            return None
        
        soup = BeautifulSoup(response.content, 'html.parser')

        # ë‚´ìš© ì¶”ì¶œ
        iframe = soup.find('iframe', {'id': 'mainFrame'})
        if iframe and 'src' in iframe.attrs:
            iframe_url = "https://blog.naver.com" + iframe['src']
            iframe_response = requests.get(iframe_url)
            if iframe_response.status_code == 200:
                iframe_soup = BeautifulSoup(iframe_response.text, 'html.parser')
                content_div = iframe_soup.find('div', {'class': 'se-main-container'})
                # ì œëª© ì¶”ì¶œ
                title_div = iframe_soup.find('div', {'class': 'se-module se-module-text se-title-text'})
                title = title_div.get_text(strip=True)
                #title = remove_substring(title_div, "\u200b")
                if content_div:
                    #ì „ì²´ ë‚´ìš©
                    content_div = content_div.get_text(strip=True)
                    content_div = remove_substring(content_div, "\u200b")
                    content_div = filter_allowed_characters(content_div)
                    content_div = fix_spacing(content_div)
                    #for i in range(0, len(content_div)):
                    #    if (content_div[i:i+2] == "  "):
                    #        content_div = content_div[:i+1] + content_div[i+2:]
                    content = content_div
                else:
                    content = 'ë‚´ìš©ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŒ'
                # ì´ë¯¸ì§€ ê°¯ìˆ˜
                images = iframe_soup.find_all('img')
                image_count = str(len(images))
            else:
                content = 'ë‚´ìš©ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŒ'
                image_count = '0'
        else:
            content = 'ë‚´ìš©ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŒ'
            image_count = '0'

        # tupleë¡œ ë°˜í™˜
        return (content, title, image_count)


    except Exception as e:
        print(f"Error: {e}")
        return None

if (__name__ == "__main__"):
    blog_url = "https://blog.naver.com/cherry_27_/223665563506"
    result = crawler(blog_url)
    if result:
        print(f"Result: {result}")
    else:
        print("Invalid or unsupported Naver blog URL.")

# ì‘ì„±ì : ì´íœ˜ë¯¼
    # ì…ë ¥ : str, ë„¤ì´ë²„ ë¸”ë¡œê·¸ url
    # ë‚´ë¶€ ë™ì‘ : ë„¤ì´ë²„ ë¸”ë¡œê·¸ ë³¸ë¬¸ê³¼ ë¸”ë¡œê·¸ ì´ë¦„ë§Œì„ ì¶”ì¶œí•œë‹¤. ì´ë¯¸ì§€ê°€ ì´ ëª‡ê°œ ì‚¬ìš©ë˜ì—ˆëŠ”ì§€ë„ ê³„ì‚°
    # ì¶œë ¥ : tuple, (ë³¸ë¬¸ ë‚´ìš© : str, ë¸”ë¡œê·¸ ì´ë¦„ : str)

    #return "None" # test value
